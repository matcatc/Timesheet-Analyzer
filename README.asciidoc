Timesheet Analyzer
==================
:author: Matthew Todd
:date: 2017-09-16
:toc:
:toclevel: 4
:numbered:


== Introduction

Timesheet Analyzer is a simple tool to help analyze timesheets.
It takes in CSV file(s), which it does some number crunching on, and then generates graphs and a simple report.

Users first need to fill in their CSV file with their time.
The format of this CSV file follows this format:

.CSV Timesheet Format
----
# Comments start with #
#week identifier, charge category, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday
----

.Example CSV Timesheet
----
# Comments start with #
#week identifier, charge category, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday
# 201737
201737 , labor    , 8 , 8 , 8 , 8 , 8 , 0 , 0
201737 , sick     , 0 , 0 , 0 , 0 , 0 , 0 , 0
201737 , vacation , 0 , 0 , 0 , 0 , 0 , 0 , 0
201737 , holiday  , 0 , 0 , 0 , 0 , 0 , 0 , 0
201737 , comp     , 0 , 0 , 0 , 0 , 0 , 0 , 0
# 201738
201738 , labor    , 0 , 0 , 0 , 0 , 0 , 0 , 0
201738 , sick     , 0 , 0 , 0 , 0 , 0 , 0 , 0
201738 , vacation , 0 , 0 , 0 , 8 , 8 , 0 , 0
201738 , holiday  , 8 , 8 , 8 , 0 , 0 , 0 , 0
201738 , comp     , 0 , 0 , 0 , 0 , 0 , 0 , 0
# 201739
201738 , labor    , 4 , 0 , 8 , 8 , 8 , 0 , 0
201738 , sick     , 4 , 8 , 0 , 0 , 0 , 0 , 0
201738 , vacation , 0 , 0 , 0 , 0 , 0 , 0 , 0
201738 , holiday  , 0 , 0 , 0 , 0 , 0 , 0 , 0
201738 , comp     , 0 , 0 , 0 , 0 , 0 , 0 , 0
----

In the above example scenario, we have 3 separate weeks listed.
In work week 37 of 2017 (`201737`), we worked a full 40 hour work week.
In work week 38, Monday, Tuesday, and Wednesday were holidays, and we took the rest of the week (Thursday and Friday) off as a vacation.
In work week 39, we came in Monday for half a day, before going home sick for the rest of the day.
We then took Tuesday off sick to recuperate, before working the rest of the week.

This is a somewhat trivial example which shows some of the capabalities.
A few things to note:

* Time spent does not need to add up to 8 hours.
Put the time you actually worked, that way the analysis will be more useful for you.

* There are multiple lines for each week, thereby easily allowing you to specify and see where the time was spent.

* For now the charge categories are hardcoded for implementation simplicity, although I would like to make them configurable in the future.


== Informal Requirements

This is a list of informally specified requirements.

.Requirements
[options="header", cols="1,7,7"]
|===
| ID
| Description
| Rationale / Comment

| 001
| Input files must be in a CSV file format.
| Makes interoperating with other programs (e.g.: spreadsheets easier). Makes it easy to edit the input files as well.

| 002
| Input files must support different charge categories.
| Makes analyzing where the time is spent easier, rather than just having a total "work time" number.

| 003
| Input files must allow for comments.
| Users may want to document their timesheets with notes for themselves.

| 004
| If an input file is missing a category, then it's equivalent to the category having all 0s for that week.
| Ease of future extensibility; ease of use.

| 005
| Weeks are specified in the input file using the ISO 8601 standard. Ex: `201736`.
| Standard.

| 006
| Generate graphs for the various "metrics" in a PNG format.
| Graphs make quickly seeing trends / behavior of the metric easier.

| 007
| Generate a simple HTML report with the graph images included.
| Makes seeing all the graphs at once easier.

| 008
| Compute the following metrics: total time worked per day, total time worked per week.
| User inputs just the parts, and we compute the totals for them (ease of use).

| 009
| Input time is in hours. Fractional hours allowed (e.g: 3.75).
| Allow users to be more precise than just hours, if desired.

| 010
| Generate a line chart of total week time with lines for the charge categories (breakdown of the total). Also a "stacked" version.
| See all charge categories in one graph. Stacked version shows how the charge categories add up to the total.

| 011
| Allow user some way of specifying a time range to analyze.
| So we don't analyze all of the weeks available, but just a subset.

| 012
| TODO: configuration of charge categories.
| Flexibility and configurability to suit user's needs.

| 013
| Temporary / intermediate CSV file is an interface (meaning format of the file should be versioned, etc.)
| If we want to allow users to use it as part of their own analysis / tooling, format should be consistent / reliable.

| 014
| Allow user to provide multiple timesheet CSV files as input.
| User can then organize their timesheets how they like (e.g.: one big file, one file per year, one file per quarter, one file per month, one file per week).

| 015
| Generate a separate line chart for an "averaged" or "smoothed" for each charge category and for the total.
| Allows for seeing a general trend in the charge categories.

| 016
| Generate a "box plot" or "candlestick plot" for total time for each day (one plot with candlesticks for each day).
| See the statistical information (mean, median, min, max, std deviation) for days. Helps see if there's any variations between days.

| 017
| Generate a histogram per charge category and total week work. Ideally also include labels in the graph for mean, median, std deviation, etc.
| See what the variation / statistics are for total time spent per week. Likewise for each charge category.

| 018
| Compute the earned comp time per week as `time_worked - 40` (i.e.: this may automatically go negative without comp time being explicitly entered in the timesheet for the week.) Accumulate/sum the earned comp time over the weeks to compute the "accrued comp time." Accrued comp time shall be computed as `accrued_previous_week + earned_this_week`.
| Useful for tracking how much comp time is being earned and accrued. This is necessary since companies will not track this information. Allow for earned comp time to be negative so that we can use the accrued comp time to track where we are in hours worked vs the 40 hour threshold.

| 019
| Generate a line chart for accumulated / accrued comp time over the course of the weeks. Include the final/current accrued comp time value in text (label or in the report).
| See trends in comp time accrual. See how much comp time is available currently.

|===


== Technical Background

=== Data Flow

Here is a schematic view of what Timesheet Analyzer does:

.Data Flow
[ditaa]
....
                                                         +---------------------+
                                                         | Gnuplot             |
                                                         | Graph Specification |
                                                         | {d} cBLU            |
                                                         +---------------------+
                                                            |
                                                            |
                                                            v
+-----------+    +--------------+    +--------------+    +---------+    +--------+
| Timesheet |--->| Computations |--->| Intermediate |--->| Gnuplot |--->| Graphs |
| CSV       |    | and          |    | Timesheet    |    +---------+    | PNG    |
|{d} cGRE   |    | Analysis cBLU|    | CSV {d} cPNK |                   | {d}cPNK|
+-----------+    +--------------+    +--------------+                   +--------+
                                                                            |
+----------+                +---------------+                               |
| Report   |--------------->| Asciidoc(tor) |<------------------------------+
| Template |                +---------------+ 
| {d} cBLU |                        |
+----------+                        |
                                    |
                                    v
                                +--------+
                                | Report |
                                | HTML   |
                                | {d}cPNK|
                                +--------+

Legend
+--------------------------------+
| Part of Timesheet Analyzer cBLU|
+--------------------------------+
| User Input                 cGRE|
+--------------------------------+
| Generated Files            cPNK|
+--------------------------------+
....

I think it's relatively self-explanatory what is occurring, but I want to explain the reasoning behind why I chose to set it up this way.
First, you'll notice that the there are several processing steps at work here.
I.e.: Timesheet Analyzer is _not_ just a single program, but several programs working in concert.
I made this choice for several reasons:

* Use of existing software: asciidoc(tor) and gnuplot
* Separation of concerns: computing metrics, generating graphs, and generating the final report.
* Formatting of the report is simple asciidoc
* Generation and formatting of the graphs is plain gnuplot code
* Allows for others to re-use or more easily extend one of these components
* More "unix-like"

Second, the above is a data pipeline.
Meaning that we can do standard things that we normally do with such pipelines.
Example: use a build system (`make`-like thing) in order to manage it.
So Timesheet Analyzer is essentially a build system, where there are three inputs:

* User's timesheet file
* Gnuplot file (graph template)
* Asciidoc file (report template)

And three outputs:

* Temporary timesheet file - which user can pipe to their own programs
* Graph images - which can be viewed individually or printed
* HTML report - the main output

In practice users will only modify their timesheet file, and will mainly only be interested in the final HTML report or occasionally the graph image files.


=== Computation and Analysis Component Overview

The Computation and Analysis Component ("comp" for short) is responsible for taking in the user provided timesheet file(s) and generating a single intermediate timesheet file for use in generating the graphs.
In short, it's a data processesing pipeline, which looks like this:

.Comp Component Dataflow
[graphviz]
----
digraph G
{ 
    rankdir=TB;
    node [shape=record]

    legend [label="Step|Haskell Data Struct|Number of elements"]

    // Defining the nodes (and their attributes)
    input_timesheets [label="Input timesheets|[Filename]|num_files"]
    list_of_lines [label="List of lines|[String]|num_weeks * num_categories"]
    converted_data_struct_per_week [label="Converted to data struct for week|[DataStruct]|num_weeks * num_categories"]
    filter_empty [label="Filter empty|[DataStruct]|num_weeks * num_categories"]
    group_by_week [label="Group by week|[[DataStruct]]|num_weeks [num_categories]"]
    merge_per_week [label="Merge per week|[DataStruct]|num_weeks"]
    sort_weeks [label="Sort Weeks|[DataStruct]|num_weeks"]
    compute_weekly_metrics [label="Compute weekly metrics|[DataStruct]|num_weeks"]
    prep_for_writing [label="Prep for writing|[String]|num_weeks"]
    intermediate_timesheet [label="Intermediate timesheet|Filename|1"]

    
    // Defining the edges / relationships between nodes
    input_timesheets -> list_of_lines -> converted_data_struct_per_week -> filter_empty -> group_by_week -> merge_per_week -> sort_weeks -> compute_weekly_metrics -> prep_for_writing -> intermediate_timesheet
}
----

In this flow, `DataStruct` is a Haskell data type which represents all of the information about a particular week.
I.e.: it includes all 7 days, all categories, and all computed metrics (e.g.: total for all categories and overall total).
The key thing to note here is that this data type supports a `fold` or `union` operation which allows for merging two of them together.
We leverage this in order to simplify things.

When we read in the timesheet data from the multiple user provided timesheet files, the information for a particular week is spread out over multiple lines, which may or may not be contigious.
So we convert each and every line into a data structure.
Since one line only contains the data for one category (e.g.: labor but not sick, vacation, etc.), the data structure will be incomplete.
But we'll have N of these data structs for N categories, which can then be merged to create a single data struct for the week.
We then compute metrics (e.g.: total time per category and overall total) and merge this into the final data struct for the week.

To make merging of data structures work, we group all of the data structures by week, thus giving us a list of data structs per week.
Then we can simply do a fold on each of these list of weekly data structures and generate the final data structure.

One minor detail is removal of "empty" weeks.
Since weeks where there is no data (0 hours for all items) should not be included in the generated intermediate graph (as it'll throw off the generated graphs), we filter them out.
Note: this is referring to having "empty" weeks at the beginning or end of the data in the intermediate timesheet.
Since it's easy enough, we do the filtering at the start so that we can pare down our lists sooner and not process them (and waste time later on).

TODO: is it ok to have missing data in the middle? Test and update this section accordingly.

We also need to sort the weeks so that when generating the graphs the x axis goes in order of time.
Since the time format we're using is "YYYYDD" (e.g.: "201738"), lexicographical sorting works fine for this.


=== Files in this project

Here is a brief overview of the files in this project:

* I chose to write the "Computation and Analysis" ("comp" for short) in Haskell, although I imagine Python, R, and a few other languages would have worked well.
See `Comp.hs`.

* Generating the graphs is done via http://gnuplot.info[Gnuplot].
See `graph.gnuplot`.

* Generating the report is done via http://asciidoctor.org[Asciidoctor] or http://www.methods.co.nz/asciidoc/[Asciidoc] (same as this README).
See `report.asciidoc`.

* And for the top-level program, I chose to use basic shell script.
See `timesheet_analyzer`
** However, I am considering eventually switching over to Haskell with the http://shakebuild.com[Shake] build system (same used to build this project as a whole.)
So that the top level program would literally be a build system.
But I have concerns as to usability in this scenario, and want to focus on delivering what really matters first.

* Also included is a template user timesheet: `timesheet_template.csv`.


== Pre-requisites for Using

* Timesheet Analyzer is installed
* http://gnuplot.info[Gnuplot] is installed
* http://asciidoctor.org[Asciidoctor] or http://www.methods.co.nz/asciidoc/[Asciidoc] is installed

When installing via the Debian package, dependencies should be automatically handled.
TODO: verify / update this statement once we've created the Debian package.

== Pre-requisites for Building

* ghc
* libghc-cassava-dev
* TODO: Shake
* Asciidoctor is installed, with http://asciidoctor.org/docs/asciidoctor-diagram/[asciidoctor-diagram] extension

== Version History

* dev :: Creation

== License

Currently the code / project is not licensed, meaning that it is copyrighted code, etc.
However, once I've gotten everything working and I'm ready, I plan on GPL'ing it.
But for now I will focus on implementing it, since that's what really matters.
If you see this and I haven't GPL'd it yet, please feel free to reach out to me.

== Website

Official Website :: TODO

Github :: TODO (once GPL'd)

